\documentclass[10pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{float}
\usepackage{tabularx}

% Define numbered environments
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{example}[theorem]{Example}

% Define various symbols
\newcommand{\character}{\alpha}
\newcommand{\naturalnumbers}{\mathbb{N}}
\newcommand{\booleans}{\mathbb{B}}

% Function symbols
\newcommand{\arity}{\alpha}
\newcommand{\symbols}{\mathcal{S}}
\newcommand{\functionsymbols}{\mathcal{F}}

% Lists
\newcommand{\listempty}{[\,]}
\newcommand{\listconcat}{\texttt{+\!+}}
\newcommand{\lists}{\mathcal{L}}

% Terms
\newcommand{\terms}{\mathcal{T}}
\newcommand{\head}{\mathsf{head}}

% Implementation
\newcommand{\function}{\textsf{function}}
\newcommand{\args}{\textsf{args}}
\newcommand{\streamout}{\textsf{write}}
\newcommand{\streamin}{\textsf{read}}
\newcommand{\reference}[1]{\textsf{ref}(#1)}

\let\oldReturn\Return
\renewcommand{\Return}{\State\oldReturn}
\renewcommand{\gets}{:=}

\newcommand{\name}{\textit{name}}
\newcommand{\tarity}{\textit{arity}}

\newcommand{\referencecount}{\textit{reference-count}}

\newcommand{\allocate}{\textsf{allocate}}
\newcommand{\deallocate}{\textsf{deallocate}}
\newcommand{\create}{\textsf{create}}
\newcommand{\writesymbol}{\textsf{write-function-symbol}}
\newcommand{\ceil}[1]{\textsf{ceil}(#1)}
\newcommand{\pop}[1]{\textsf{pop}(#1)}
\newcommand{\push}[1]{\textsf{push}(#1)}
\newcommand{\peek}[1]{\textsf{peek}(#1)}
\newcommand{\sempty}[1]{\textsf{empty}(#1)}

\newcommand{\blocks}{\textsf{blocks}}
\newcommand{\freelist}{\textsf{freeList}}
\newcommand{\elementsperblock}{\textsf{ElementsPerBlock}}
\newcommand{\currentindex}{\textsf{currentIndex}}

% Others
\newcommand{\cpp}{\texttt{C++}}
\newcommand{\ie}{\emph{i.e.}}

\author{Maurice Laveaux}
\title{mCRL2 Term Library}

\begin{document}
\maketitle

\begin{abstract}
\noindent This document contains a description of the term library as implemented in the mCRL2 toolset.
Its contents are listed below.
\end{abstract}

\tableofcontents

\newpage
\section{Preliminaries}\label{section:definitions}

Let $\functionsymbols = \biguplus_{i \in \naturalnumbers} \functionsymbols_i$ be a \emph{ranked} alphabet of  \emph{function symbols}.
A function symbol $f \in \functionsymbols_i$ is said to have a rank or \emph{arity}, given by $\arity(f)$, equal to $i$.
The set of terms $\terms$ is the smallest set such that for $t_0, \ldots, t_n \in \terms$ and $f \in \functionsymbols_n$ it holds that $f(t_0, \ldots, t_n) \in \terms$, as such $\functionsymbols_0 \subseteq \terms$.
For each term $f(t_0, \ldots, t_n)$ we say that $f$ is its \emph{head}, denoted by $\head(f(t_0, \ldots, t_n))$, and we define a function $\args(f(t_0, \ldots, t_n))$ to be equal to a sequence of terms $[t_0,\ldots,t_n]$.

There are several useful classes of terms that can be identified.
One example is the class of \emph{list} terms. 
Let $\listconcat \in \functionsymbols_2$ and $\listempty \in \functionsymbols_0$ be function symbols to define list concatenation and the empty list.
The set of \emph{list} terms $\lists \subseteq \terms$ is the smallest set such that $\listempty \in \lists$ and for terms $t \in \terms$ and $l \in \lists$ the \emph{concatenation} $\listconcat(t, l) \in \lists$.
There are also other classes, such as \emph{term string} where a string is stored as part of the function symbol name and \emph{binary tree} where every left and right sub-tree is stored as arguments.
These can all be represented in our term library.

\section{Term Library}\label{section:library}

The term library provides the storage (in memory and on disk) of terms and function symbols. 
Formally, the term library stores a finite subset of terms $\terms' \subseteq \terms$.
The library has been designed with the following goals in mind:

\begin{enumerate}
	\item Minimize the amount of memory used to store the set of terms.
	
	\item Fast creation (and deletion) of terms.
	
	\item Fast comparison, in particular equality, between terms.
\end{enumerate}

\subsection{Application Programming Interface}

The library is implemented in the $\cpp 11$ compliant subset of the $\cpp$ language.
We assume some familiarity with the concepts of $\cpp$, for now the distinction between classes and objects is important and the role of constructors and member functions.
A constructor is a language construct that instantiates an object of a specific class, and member functions operate on that instance.

The application programming interface (API) consists of several constructors that allow the user to create function symbols and terms. 
Function symbols are constructed from a sequence of characters to represent their name and a natural number for its arity.
The relation between the mathematical elements and these constructors are listed in Figure \ref{table:apirelation}.

\begin{figure}[H]
\begin{center}
\begin{tabular}{|l|l|}
  \hline
Definition & API \\ \hline
$\texttt{name} \in \functionsymbols_n$ & $\text{function\_symbol}(\texttt{name}, n)$ \\ \hline
$f(t_0, \ldots, t_n) \in \terms$        & $\text{term\_appl}(f, t_0, \ldots, t_n)$ \\ \hline
\end{tabular}
\end{center}
\caption{The relation between the definition and the API}\label{table:apirelation}
\end{figure}

\noindent For the already identified classes of terms there are specific constructors defined as shown in Figure~\ref{table:apisubclasses}.

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{|l|l|}
      \hline
      Definition & API \\ \hline
      $\listempty \in \functionsymbols_0$ & \verb|function_symbol(<empty_list>,0)| \\ \hline 
      $\listconcat \in \functionsymbols_2$ & \verb|function_symbol(<list_constructor>,2)| \\ \hline 
      $\listconcat(t, l) \in \lists$ & \verb|term_list(t, l)| \\ \hline
    \end{tabular}
  \end{center}
  \caption{The relation between the list class and the API}\label{table:apisubclasses}
\end{figure}

\noindent There are also additional member functions to check equality (or inequality) between terms.
Note that there is not really a semantic inequality between terms defined, but from an implementation viewpoint this is useful to have.

There are also several member functions to access the information carried by a term. 
There is a \verb|function| function maps a term to its head function symbol. 
The \verb|arg| function takes a term and an index as input and returns the argument term at the specified index.

Finally, we also provide the ability to write a term to \emph{stream} and subsequently retrieve the term from this stream.
In particular, the ability to write multiple individual terms to a stream is provided.
For this we provide the function $\streamout(s, t)$ to write term $t$ to a stream $s$, which is a sequence of bits or characters, and symmetrically read a term from a stream by means of $\streamin(s)$, which returns this term.

\subsection{Architecture}\label{section:implementation}

The main architectural choice for this library is that terms and function symbols are maximally shared, by a technique called \emph{hash conscing}.
Here, every function symbol and term has a unique identifier and these identifiers are used by a term as references to its head function symbol and arguments.
This sharing facilitates the goal to minimize memory usage by the stored terms and also allows for constant time comparison, because the identifiers can be compared in constant time.
The inequality between terms is determined by the natural order of these identifiers, which are natural numbers.

This functionality is implemented by an underlying function symbol \emph{pool} class that stores the finite subset of function symbols $\functionsymbols'$ and a term pool to store the finite subset of terms $\terms'$.
To facilitate ease of programming on a high-level this sharing is completely transparent to the programmer, which instantiates an object that internally stores an identifier to look up the information about the underlying function symbol (or term).

For the purpose of deleting shared elements there is a \verb|shared_reference| class that internally counts the number of references to each term or function symbol.
Here, a reference means that another term has that identifier as head symbol or argument.
The \texttt{term} and \texttt{function\_symbol} classes internally use this class to keep track of the number of references.

\section{Function Symbol Pool}

Now, we are going to dive into specific implementation details and need to be a little more concrete.
An important concept of $\cpp$ are its (simplified) memory model, where there is a \emph{heap} that maps positions, also called \emph{pointers} or \emph{references}, to an array of bits, or in general data are now important.
We use a $(\name, \tarity)$ pair to indicate the information stored on the heap about the function symbol.
Where two function symbols with the same name and arity are equivalent.
The function symbol pool has a member function named \verb|create| to obtain the identifier to the function symbol with the given name and arity.
This identifier is the reference to the data stored on the heap.

\begin{itemize}    
  \item \create(name : String, arity : Nat) : $\naturalnumbers$
\end{itemize}

\noindent The implementation of the \create function is given Algorithm~\ref{alg:create_function_symbol}.
The set of identifiers $\functionsymbols'$, and later $\terms'$, is a set with polymorphic lookup where the identifier can be found using the $(\name, \tarity)$.
We introduce the notation $\functionsymbols'[(\name, \tarity)]$ to indicate the partial function mapping the arguments to the identifier, which yields $\bot$ when the element is not in the set.
Note that although $\functionsymbols'$ is a set of identifiers on to elements on the heap it also directly stores the finite set of function symbols.
The $\allocate$ function reserves space on the heap and stores the $\name$ and $\tarity$ pair in the reserved space.
In the actual implementation this is a separate constructor for a pair-like object.

\begin{algorithm}[H]
 \caption{Creation of function symbols}\label{alg:create_function_symbol}
 \begin{algorithmic}[1]
  \Procedure{create}{$\name, \tarity$}  
  \If {$\functionsymbols'[(\name, \tarity)] \neq \bot$}
	 \State {\textbf{return} $\functionsymbols'[(\name, \tarity)]$}
  \EndIf
  
  \State {$f \gets \allocate(\name, \tarity)$}
    
  \State {$\functionsymbols' \gets \functionsymbols' \cup \{f\}$}
  \State {\textbf{return} $\reference{f}$}
  \EndProcedure
\end{algorithmic}
\end{algorithm}

\noindent The resulting identifier is then used by $\textsf{function\_symbol}$ to look up the underlying information about the function symbol.

To clean up, \ie, removing the underlying data from the heap, objects with a reference count of zero there are two different approaches.
The first method immediately cleans up the function symbol from $\functionsymbols'$ and the heap whenever its reference count becomes zero in its destructor.
This approach will be referred to \emph{direct-destruction}. 
Another approach is to periodically remove all function symbols with a reference count of zero. 
This approach will be referred to as \emph{garbage collection}.

For function symbols the \emph{direct-destruction} method is used as the number of function symbols that is destroyed is typically very low.
This destructor that is called when $f$ goes out of scope is implemented by the \verb|destroy| function defined below.

\begin{algorithm}[H]
 \caption{Destruction of function symbols}\label{alg:destroy_function_symbol}
 \begin{algorithmic}[1]
  \Procedure{destroy}{$f$}  
  \State {$deallocate(f)$}    
  \State {$\functionsymbols' \gets \functionsymbols' \setminus \{f\}$}
  \EndProcedure
\end{algorithmic}
\end{algorithm}

\noindent The \emph{deallocate} function frees the identifier to be used again by a different function symbol.

\section{Term pool}

The term pool is the class that stores the set of terms $\terms'$ and is very similar to the function symbol pool.
The \emph{create\_appl} can be used to create new terms, we refer to terms with arguments as \emph{function applications}.

The constructor of a function application calls the following function to obtain a reference to an existing or new term.

\begin{itemize}    
	\item create\_appl(f : $\functionsymbols$, $t_0, \ldots, t_n : \terms$) : $\naturalnumbers$
\end{itemize}

\noindent The implementation of this function can be seen in Algorithm~\ref{alg:creation}.
The function symbol $f$ and terms $t_0$ to $t_n$ should be elements of the current subset of stored function symbols $\functionsymbols'$ and terms $\terms'$ respectively, which means that they are identifiers.
Note that on the heap a tuple $(f, c, t_0, \ldots, t_n)$ is stored that encodes the actual term with $c \in \naturalnumbers$ be a reference counter.

For terms we use the garbage collection approach, where garbage collection is triggered based on some heuristics.
The advantage of garbage collection is that terms with a reference count of zero can be reused when they are recreated before being destroyed.
This means that only its reference counter must be increased.
In practice, this occurs quite often as the volume of terms being created and destroyed during term rewriting is quite large.

\begin{algorithm}[H]
 \caption{Creation of term applications}\label{alg:creation}
 \begin{algorithmic}[1]
  \Procedure{create\_appl}{$f,t_0,\ldots,t_n$}  
  \If {$\terms'[f, t_0,\ldots, t_n] \neq \bot$}
	 \State {\textbf{return} $\terms'[f, t_0,\ldots, t_n]$}
  \EndIf
  
  \State {$t \gets \text{construct}(f,t_0,\ldots,t_n)$}
  
  \If {should-collect-garbage()}
   \State {collect()}
  \EndIf
  
  \State {$\terms' \gets \terms' \cup \{t\}$}
  \State {\textbf{return} $t$}
  \EndProcedure
\end{algorithmic}
\end{algorithm}

\noindent The boolean function \emph{should-garbage-collect} is used to decide when garbage collection should be performed.
The garbage collection itself is implemented by the \emph{collect} function.
Currently the \emph{should-garbage-collect} function is implemented by using a counter that is decremented on every call to \emph{should-garbage-collect}.
Whenever this counter reaches zero the function returns true.
During garbage collection this counter is then set to the number of terms in $\terms'$, which is equal to $|\terms'|$.

\subsection{Garbage Collection}

The garbage collection is implemented by calling destroy on every term with a reference count of zero, as shown in the following pseudocode:

\begin{algorithm}[H]
\caption{Garbage collection of terms}\label{alg:collect}
\begin{algorithmic}[1]
\Procedure{Collect}{}
	\For {$t \in \terms'$}
    \If {$\text{reference-count}(t) = 0$}
      \State{Destroy(t)}
    \EndIf
  \EndFor
  
  \State{collect-countdown $\gets |\terms'|$ }
\EndProcedure
\end{algorithmic}
\end{algorithm}

\noindent The \emph{destroy} method recursively destroys all arguments which have a single reference, because that reference is the current function application.

\begin{algorithm}[H]
\caption{Destroying individual terms}\label{alg:destroy}
\begin{algorithmic}[1]
\Procedure{Destroy}{$t \in \terms'$}
  \For {$p \in \args(t)$}
    \If {$\referencecount(p) = 1$}
      \State {Destroy($p$)}    
    \EndIf
  \EndFor
  
  \State {$\terms' \gets \terms' \setminus \{t\}$}
  \State {deallocate($t$)}
\EndProcedure
\end{algorithmic}
\end{algorithm}

\noindent The \emph{deallocate} function frees the heap memory used by this term.
Note that this function prematurely destroys arguments with a single reference count. 
The reason for this is that the function \texttt{arg} is no longer defined for $t$ after it has been deallocated.

\section{Binary Input/Output}

We provide two different streaming procedures to share terms between tools of the toolset.
The first method uses the concrete syntax and operators on streams of characters.
A function symbol $f(t_0, \ldots, t_n)$ is simply written to the character stream as the name of $f$ written as ``f'', followed by recursively printing all its arguments $t_0$ to $t_n$ separated by commas and a closing bracket at end.
For convenience of reading, list terms are printed as a sequence of their elements surrounded by square brackets.
The reading procedure simply parses the characters of the input stream and reconstructs the corresponding terms.

Although this is useful for debugging it is not a very efficient exchange format as sharing of function symbols of terms cannot be employed and characters themselves are very verbose.
Therefore, we have developed the streamable binary (a)term format (SBAF).
A single term can be written to and read from a \emph{binary} streams in SBAF one at the time and terms in the same stream share their arguments.
We focus on writing terms first and then show how the resulting stream can be used to reconstruct the written terms during reading.

Similar to the in-memory storage, a (different) unique identifier is assigned to each term and function symbol that is used to identify arguments during writing.
The output is going to consist of \emph{packets} that either represent a function symbol, a term or a subterm indicated by two bits in the header of a packet.
We use one, two and three respectively to represent these headers.
The difference between a term and a subterm is that a term is returned from $\streamout(s)$, where $s$ is a stream, and the subterms are (as their name suggest) subterms of the retrieved term.

The unique identifier for each written element is stored by a mapping from function symbol and terms to a natural number.
This is done in a data structure called an \emph{indexed set} that increments a consecutive index whenever an element is inserted and assigns it to the new element.
Note that we are never going to remove elements from this set so the indices are always compact.

Binary streams are not directly facilitated by the $\cpp$ library so we have implemented a \texttt{bitstream} class that is able to write (and read) individual bits from and to a stream.
It also provides several convenience functions to write character sequences and integers to this stream, where integers are stored using a \emph{variable width} encoding, where we use the overloads $\streamout(s,$ ``string'') and $\streamout(s, n)$, with $n \in \naturalnumbers$.
Furthermore, we use the notation $n_i$ for some natural number $n$ to indicate that only $i$ bits of the binary encoding of this number are considered when writing it, instead of relying on the variable width encoding.

Let $I$ be an indexed set of function symbols.
Algorithm~\ref{alg:write_symbol} shows how an individual function symbol is written to a stream $s$.
First, we check whether the function symbol was already written, which means that it has an index $n$.
Otherwise, there are only three distinct packets so only two bits are needed to encode it.
After which the name and arity of the function symbol are written and a new index $n$ is created for this function symbol.

\begin{algorithm}[H]
  \caption{Writing a function symbol to an output stream $s$}\label{alg:write_symbol}
  \begin{algorithmic}[1]
    \Procedure{\writesymbol}{$s, f \in \functionsymbols'$}
    \If {$(f, n) \in I$}
      \Return $n$
    \Else
      \State {$\streamout(s, 0_2)$}
      \State {$\streamout(s, \name(f))$}
      \State {$\streamout(s, \tarity(f))$}
      \State $I \gets I \cup \{f\}$
      \Return $n$ such that $(f, n) \in I$
    \EndIf
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\noindent Let $J$ be an indexed set of terms.
Algorithm~\ref{alg:write_term} shows the implementation to write a term to the stream $s$.
We write terms such that the arguments (and head symbol) of a term are written to the stream before the term itself by traversing the term bottom up.
This can achieved by maintaining stack of terms where each term has a value $\{\top, \bot\}$ associated to it to indicate whether its arguments have already been processed.
The bottom up traversal is implemented by first changing the flag for $t'$ from $\bot$ to $\top$ and then inserting all arguments that are not already in $I$ (as these have already been written) to the stack.
We must also maintain that the term taken from the stack has not been inserted to $I$ in the meantime, which can happen whenever the same subterm occurs multiple times.

The case where the term is actually written to the stream, indicated by $b = \top$, starts by writing obtaining the function symbol index and possibly writing a function symbol packet to the stream. 
Then, the packet identifier (again using 2 bits) is written, which is an output term whenever the current term is equal to $t$ and a subterm otherwise.
Then the indices of the function symbol and each argument (which should already be included in $I$) are written to the stream.
Note that we only need $\ceil{\log(|I|) + 1}$ bits to uniquely identify previously written subterms and function symbols.
During reading we also know the number of terms that have been written and as such the number of bits to read can be inferred.
Finally, the written term is stored in the indexed set $I$.

\begin{algorithm}[H]
  \caption{Writing a term to an output stream $s$}\label{alg:write_term}
  \begin{algorithmic}[1]
    \Procedure{Write}{$s \in \booleans^*, t \in \terms'$}
    \State {$J \gets \emptyset$}
    \State {$Q \gets \{ (s, \bot) \}$}
      
    \While {$\neg\sempty{Q}$}    
      \State {$(t', b) \gets \pop{Q}$}
        \If {$\neg \exists n \in \naturalnumbers : (t', n) \in J$}
          \If {$b = \top$}
            \State {$n \gets \writesymbol(\head(t'))$}
            
            \If {$t' = t$}
              \State {$\streamout(s, 1_2)$}
            \Else
              \State {$\streamout(s, 2_2)$}
            \EndIf
            
            \State {$\streamout(s, n_{\ceil{\log(|I|)+1)}})$}
            
            \For {$p \in \args(t')$}
              \State {$i$ such that $(i, i) \in I$}
              \State {$\streamout(s, i_{\ceil{\log(|J|)+1)}})$}              
            \EndFor   
            
            \State {$I \gets I \cup \{t'\}$}       
          \Else
            \State {$\push{Q, (t', \top)}$}
            \For {$p \in \args(t')$}
              \If {$\neg \exists n \in \naturalnumbers : (p, n) \in J$}
                \State {$\push{Q, (p, \bot)}$}
              \EndIf
            \EndFor        
          \EndIf
        \EndIf
    \EndWhile
    \Return {$s$}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\noindent We present a small example to illustrate this algorithm.

\begin{example}
  Let us consider writing the term mult(s(s(z)), s(z)) to a stream, which is the example presented in~\cite{BJKO99}.
  Again, we use the subscript to indicate the number of bits of that number written to the stream.
  To write a string we first write its length, followed by $n$ characters using 8 bits per character.
  For numbers smaller than 128 we need eight bits in our variable-width encoding.
  The resulting writes and the values for $I$ and $J$ are presented in the following table.
  Table~\ref{table:output} shows the steps needed to write mult(s(s(z)), s(z)) to a stream, indicating the values written to the stream, the number of bits needed and the values of $I$ and $J$.
  
  \begin{table}
  \caption{Shows the steps needed to write mult(s(s(z)), s(z)) to a stream, indicating the output written to the stream, the number of bits needed and the values of $I$ and $J$.}\label{table:output}
  
  \begin{center}
  \scriptsize
  \begin{tabular}{|l|l|l|l|l|l|}
    \hline
    Term & Function Symbol & Output                 & Size (b) & I            & J \\ \hline
         & z               & $0_2\,1_8$``z''$\,0_8$ & 26       & $\{(z, 0)\}$ &   \\ \hline
    z    &                 & $1_2\,0_1$             & 3        & $\{(z, 0)\}$ & $\{(z, 0)\}$ \\ \hline
         & s               & $0_2\,1_8\,$``s''$\,1_8$ & 26     & $\{(z, 0),(s, 1)\}$ & $\{(z, 0)\}$ \\ \hline
    s(z) &                 & $1_2\,1_1\,0_1$        & 4        & $\{(z, 0),(s, 1)\}$ & $\{(z, 0),(s(z), 1)\}$ \\ \hline
    s(s(z)) &              & $1_2\,1_1\,1_1$        & 4        & $\{(z, 0),(s, 1)\}$ & $\{(z, 0),(s(z), 1),(s(s(z)), 2)\}$ \\ \hline
         & mult            & $0_2\,4_8\,$``mult''$\,2_8$ & 50  & $\{(z, 0),(s, 1),(mult,2)\}$ & $\{(z, 0),(s(z), 1),(s(s(z)), 2)\}$ \\ \hline
     mult(s(s(z)), s(z)) & & $2_2\,2_2\,2_2\,1_2$ & 8 & - & - \\ \hline     
  \end{tabular}
  \end{center}
  \end{table}

  \noindent So writing this term requires 121 bits in total.
  Typically the ratio of terms to function symbols is quite high, so the small number of bits needed to encode the terms is the most important.
\end{example}

\noindent There are two separate indexed sets for function symbols and terms such that the resulting indices are kept smaller.
Furthermore, in practice we also allow a function over terms to be used during writing (and reading) that is applied to each subterm before the term is written to a stream.
This can be useful to remove some implementation details from the terms that should not shared between tools.

The symmetric reading function is implemented in Algorithm~\ref{alg:read_term}.
Upon initialization of the stream $I$ and $J$ are set to $\emptyset$ and these indexed sets should be maintained in between calls to reading terms.
Reading from a stream has additional auxiliary functions $\streamin_{\textit{bits}}(s, n)$, $\streamin_{\naturalnumbers}(s)$ and $\streamin_{\textit{string}}$ to reads $n$ bits, numbers and characters from the stream $s$ respectively.
Again, we use an indexed set $I$.
However, in the implementation we can use an array to efficiently map indices to elements in this set as the indices grow strictly increasing and the mapping is injective.

\begin{algorithm}[H]
  \caption{Writing a term to an output stream $s$}\label{alg:read_term}
  \begin{algorithmic}[1]
  \Procedure{Read}{$s \in \booleans^*, t \in \terms', I, J$}
    \State {$p \gets \streamin_{\textit{bits}}(s, 2)$}
    
    \If {$p = 0$}
      \State {$\name \gets \streamin_{\textit{string}}(s)$}
      \State {$\tarity \gets \streamin_{\naturalnumbers}(s)$}
      \State {$I \gets I \cup \{(\name, \tarity)\}$}
    \Else
      \State {$f$ such that $(f, \streamin_{\textit{bits}}(s, \ceil{\log(|J|)+1)}) \in I$}
      \State {$Q \gets [t_0, \ldots, t_{\tarity(f)}]$}
      \For {$i \in Q$}
        \State {$t_i$ assigned such that $(t_i, \streamin_{\textit{bits}}(s, \ceil{\log(|J|)+1)}) \in I$}
      \EndFor
      \State {$t \gets f(t_0, \ldots, t_{\tarity(f)})$}
      
      \If {$p = 2$}
        \Return {$t$}
      \Else
        \State {$J \gets J \cup \{t\}$}
      \EndIf
    \EndIf
  \Return {$s$}
  \EndProcedure
\end{algorithmic}
\end{algorithm}

\noindent In the implementation a special function symbol exists to mark the end of the stream.

Previously an alternative format, called binary aterm format, described in~\cite{BJKO99} was used to write terms into streams.
This previous format allowed better compression by counting the occurrences of all terms at all argument positions beforehand and minimizing the amount of bits needed to encode this information.
Although this method allowed presumably optimal compression it could only write a single term (with sharing) to the stream and required a lot of book keeping while traversing the term twice.
However, for labelled transition systems, which are typical output terms, the bulk of information is the list of transitions.
To encode this list of transitions as a single term the previously mentioned class of list terms was used.
This meant that first this enormous term had to be constructed, then traversed depth-first twice (incurring quite some memory overhead), followed by writing this term to the stream, where all transitions could occur at the first position of the list concatenation term.

The new method avoids the construction of this list term as transitions can be written to the stream individually.
Furthermore, the width of indices assigned to transition terms simply scale logarithmically in the number of transitions, which yielded a better (both in space and time) term format.
Writing the example term mult(s(s(z)), s(z)) in the old format required a table of 140 bits and then 5 bits to write the term itself.
Even though the new format uses more bits to write this term it is much more straightforward to process and in practice it performs (much) better.
 
\section{Data Structures}

In this section the data structures in the underlying implementation are described in more detail.

\subsection{Reference Counting}

The shared reference is implemented by a class named \texttt{shared\_reference} which consists of a reference and a reference counter. 
The invariant states that the reference counter is always equal to the number of instances that point to the same referred term. 
In $\cpp$ there are a number of operators to construct, move and copy classes.
A move is an operator where an object is constructed from another object, but the other object can be left in an undefined state.
The reference count invariant is satisfied by implementing these operations in the following way:

\begin{enumerate}
  \item When a \texttt{shared\_reference} instance is constructed from a reference its reference count is incremented by one.
  
  \item When a \texttt{shared\_reference} instance is copy-constructed its reference count is incremented by one.
  
  \item When a \texttt{shared\_reference} instance is move-constructed the reference count is kept the same, but the\texttt{shared\_reference} instance that was moved from will become a null reference.
  
  \item When a \texttt{shared\_reference} instance is assigned to its current reference count is decremented by one.
  The reference count of the assigned reference is incremented by one.
  
  \item When a \texttt{shared\_reference} instance is move-assigned its current reference count is decremented by one. The \texttt{shared\_reference} instance that was moved from will become a null reference.
  
  \item When a \texttt{shared\_reference} is destructed the reference count will be decremented by one. 
\end{enumerate}

\noindent For terms and function symbols all shared references are constructed with a default term or function symbol respectively. 
Whenever the reference count for a reference is equal to zero the referred to term can be cleaned up, except for the default that always maintained a reference count of at least one.
In the case of function symbols this immediately triggers the destroy function.

\subsection{Hash table}

\newcommand{\hnr}{\textit{hnr}}
\newcommand{\hash}{\textsc{hash}}
\newcommand{\combine}{\textsc{combine}}

The references to terms and functions symbols are both stored in a set which provides constant time insertion $\cup$, deletion $\setminus$ and contains $\in$ functions.
These sets store pointers to the elements allocated on the heap.
This can be efficiently implemented by using a hash table.
As typical for a hash table it requires a hash function and an equivalence check for its elements to implements it operations.

Our hash function, which is an operator to natural numbers, for terms is determined by a suitable combination of the underlying references as shown in Algorithm~\ref{alg:hash_term}.
For terms the hash function is defined by combining the values of all the references.
For performance reasons it is furthermore desirable to be able to compute the hash function and equivalence check without (temporarily) instantiate elements of that type.

\begin{algorithm}[H]
 \caption{Hashing terms}\label{alg:hash_term}
 \begin{algorithmic}[1]
  \Procedure{hash}{$f, t_0, \ldots, t_n$} 
  \State {$\hnr \gets \hash(f)$}
  \For {$t \in \{t_0, \ldots, t_n\}$}
    \State {$\hnr \gets \combine(\hnr, t)$}
  \EndFor 
  \State {\textbf{return} $\hnr$}
  \EndProcedure
\end{algorithmic}
\end{algorithm}

\noindent In practice it is quite subtle what a good (and fast) $\combine$ function is that ensures a fairly random distribution of hash values.
For function symbols the hash is obtained from hashing the name string and its arity and returning its combination.
Note that $f$ is a reference to a function symbol and as such it does not require this expensive computation, but the hash is just derived from the given reference (or pointer).
It is straightforward to also derive functions that can be applied to terms and function symbols directly, which is required for rehashing.
The equivalence between terms can be determined by comparing the references their head symbols and pairwise comparing the references for its arguments.
For function symbols this is done by checking name and arity equivalence.

As the equivalence checks for terms is quite it is essential that the number of equivalence checks upon searching is minimized.
For this purpose we have chosen for an open hash table with single linked-list buckets as the probing used by closed hash table resulted in a performance reduction of ten to fifteen percent.
On the other hand, closed hash table have a reduced memory footprint so there is trade off.

\section{Optimizations}\label{section:optimizations}

There are several optimizations that have been done on the previously described implementation.

\subsection{Term Pool per Arity}

Most terms only have a small number of arguments. 
Let $k$ be a constant such that a term is \emph{small} whenever its head symbol has an arity tht is less than or equal to $k$. 
We will use $\terms^i$, for any natural number $i$, to denote a subset of $\terms$ with function symbols that have an arity equal to $i$. 

The decision procedure has constant complexity as well.
Now, instead of having one pool to store the finite subset $\terms' \subseteq \terms$, there will be a number of term pools:

\begin{itemize}
  \item For small terms, $k$ different pools to store $\terms^0 \cup \cdots \cup \terms^k \subseteq \terms'$.
    
  \item A pool to store the set of terms $\terms'' \subset \terms'$ that do no occur in the other pools, \ie, $\terms'' = \terms' \setminus (\terms^0 \cup \cdots \cup \terms^k)$.
\end{itemize}

\noindent Note that all pools are disjoint, \ie, $\terms^0 \cap \cdots \cap \terms^k \cap \terms'' = \emptyset$ and all pools combined store the whole subset, as such $\terms^0 \cup \cdots \cup \terms^k \cup \terms'' = \terms'$. 
The interface of the term pool remains unchanged. 
Internally this term pool uses the arity of a function symbol to decide which underlying pool will be used to create the term. 
For example calls to \texttt{create\_appl(f)} will always go to the pool storing $\terms^0$.

The advantage is that the complexity for all loops over the arguments of function symbols with an arity up to and including $k$ will become constant. 
This enables compiler optimizations such as loop unrolling in practice, which can have quite an effect on run time performance. 
This optimization reduces the number of branch misses which increases the effective run-time performance as well.

\subsection{Weak Reference Counting}

Here, we introduce a way to relax the reference counting for arguments of terms to reduce the number of reference count changes.
For this purpose we introduce the notion of a \emph{weak reference}.
A weak reference is a reference that does not change the reference counter of the referred to term, but might still refer other objects.
We are going to change the references to arguments of a term to be weak references, thus reducing the number of reference count changes.
However, this means that garbage collection has to be adapted, because a reference count of zero does not necessarily mean that the term is no longer referred to.

The garbage collection that is be described here is often referred to as a \emph{tracing garbage collection}. 
The basic algorithm is a two-phase where first the reachable terms are \emph{marked}, followed by a \emph{sweep} that cleans up the unmarked terms, as these are unreachable.

The marking procedure is implemented as follows.
Consider the terms as a graph where the set of vertices are given by $\terms'$ and the edges are given by the weak references between terms and their arguments.
Every term with a reference count above zero is reachable by definition, these terms form the \emph{root} set.
This has been implemented as indicated in Algorithm~\ref{alg:mark}.

\begin{algorithm}[H]
  \caption{Marking the root set}\label{alg:mark}
  \begin{algorithmic}[1]
    \Procedure{RootMark}{}
    \For {$t \in S$}
      \If {$\text{reference-count}(t) > 0$}
        \State{Mark(t)}
      \EndIf
    \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\noindent Starting from elements in this root set, we perform a search to mark the elements that can be reached by the edges in this graph.
This step is implemented by the \emph{mark} function described in Algorithm~\ref{alg:markterm}.
A term can be marked by the function \emph{set-mark} and the mark can be removed by using \emph{remove-mark}.
The function \emph{is-marked} returns true if and only if that term has been marked.
Note that marking stops whenever it find that the term has already been marked.
This is correct, because marked terms either belong to the root term or the mark function has been previously applied to them, ensuring that its arguments have already been marked.
This ensures that the subterms of shared terms are not explored again.

\begin{algorithm}[H]
  \caption{Marking reachable terms}\label{alg:markterm}
  \begin{algorithmic}[1]
    \Procedure{Mark}{$t : \terms'$}
    \If{$\neg$is-marked($t$)}
      \State{set-mark($t$)}
    
      \For {$p \in args(t)$}
        \State{Mark(p)}
      \EndFor
    \EndIf
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\noindent In the implementation this exploration is implemented depth-first and with an explicit stack to avoid excessive memory usage and stack overflow issues.

The marking of terms itself can be implemented efficiently by observing that all terms outside of the root set have a reference count of zero.
This reference count can be set to a special value (in this case max value) to indicate that it has been marked and removing the mark resets it back to zero.
Furthermore, in

After these steps we can conclude that all terms that have been marked are not reachable by the root set can be deallocated and removed from the set $\terms'$
We should also remove the mark of terms such that the next garbage collection can be performed again.
This is implemented by the \emph{sweep} function that is described in Algorithm~\ref{alg:sweep}.

\begin{algorithm}[H]
  \caption{Sweeping terms that are no reachable}\label{alg:sweep}
  \begin{algorithmic}[1]
    \Procedure{Sweep}{}
    \For {$t \in S$}
      \If {$\neg \text{is-marked}(t)$}
        \State{$S \gets S \setminus \{t\}$}
        \State{deallocate($t$)}
      \Else
        \State{remove-mark($t$)}
      \EndIf
    \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\noindent After this the heap memory used by terms that are not reachable has been freed.

\subsection{Null Term}

Instead of introducing a default term that is used whenever the \texttt{shared\_reference} is default constructed we can introduce an actual \emph{null} reference, as in the literal defined in the language.
This breaks the invariant that any term always has a valid (possibly default) shared reference.
Therefore, the \texttt{shared\_reference} must first check whether it points to a valid term before trying to adapt its reference counter.
For this purpose a function named \emph{defined} is introduced that returns true iff the shared reference is not equal to \emph{null}.

The advantage of this alternative is a removal of reference count adaptations to all instances of the default term.
In the 1394 protocol state space generation with the option \texttt{--cached} this optimization reduces the number of reference count adaptations by ten percent. The run-time performance was almost unaffected. However, in the case of atomic reference counters this had about 11 percent run time reduction for the state space exploration.

\subsection{Block Allocator}

The $\allocate$ and $\deallocate$  functions are part of the allocator interface as defined in the STL.
Note that we have combined the $\allocate$ and construct function where $\allocate$ also directly assigns the data on the heap, which is normally performed by the constructor.
Although no specific implementation is required for these functions they typically call the system interface to obtain memory from the operating system for each call.
In the Linux kernel a slab allocator is used that has no internal fragmentation for powers of two and a page size is typically 4KB. 
Compared to that, a single term of arity three only requires $40$ bytes.
This is a very small amount and also not a power of two, which is typically not optimal.

As these terms are fundamental to the operation of the tool set the number of allocated terms is typically very high.
Therefore, a useful approach to reduce the number of system calls and memory overhead is to allocate larger blocks of memory and return references into these blocks.
This is done by our \emph{block allocator}.

The block allocator has a single linked list of memory blocks called $\blocks$.
Each block can store $\elementsperblock$ number of elements.
We refer to these elements as \emph{slots} in the block that can either be free or contain an element.
The allocator stores a $\currentindex$ of the first slot in the block that has never been used.
To keep track of slots that have been freed in the mean time a \emph{free list} is used.

The \texttt{allocate} function is described in Algorithm~\ref{alg:allocate}.
First, if the free list is not empty then we return the next element in that list and remove it from the list, this is done by \texttt{pop\_front}.
If we have used all indices at least once, and the freelist is empty, then a new block is allocated and added the the $blocks$ list.
Otherwise, we take the first index in the first block that has not been used yet and update the \texttt{currentIndex} accordingly.

\begin{algorithm}[H]
  \caption{Allocate}\label{alg:allocate}
  \begin{algorithmic}[1]
    \Procedure{Allocate}{}
    \If {$\neg$freeList.empty()}
      \State {\textbf{return} freeList.pop\_front()}
    \EndIf
    
    \If {currentIndex $\geq$ ElementsPerBlock}
      \State {blocks $\gets$ blocks.push\_front()}
      \State {currentIndex $\gets 0$}
    \EndIf  
    
    \State {firstBlock $\gets$ blocks.front()} 
    \State {slot $\gets$ firstBlock[currentIndex]} 
    \State {currentIndex $\gets$ currentIndex + 1}
    \State {\textbf{return} slot}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\noindent Deallocating a term is straightforward as it just has to be added to the freelist, as shown in Algorithm~\ref{alg:deallocate}

\begin{algorithm}[H]
  \caption{Deallocate}\label{alg:deallocate}
  \begin{algorithmic}[1]
    \Procedure{Deallocate}{Reference r}
      \State {freeList.push\_front(r)}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\noindent One thing to note here is that the freelist can be efficiently implemented by storing the reference to the next element in the list in place of the free slots of the blocks.
The first slot in this free list is pointed to some variable named \emph{firstFreeSlot}.
The \emph{freeList} can then be stored by storing the \emph{next} reference, which contains the reference to the next element in the list, in place of the slots.
We define the invariant that all slots that are reachable by following next references after \texttt{firstFreeSlot} are part of the freelist.
This means that the \emph{freeList} is empty when the \emph{firstFreeSlot} points to null.
The \emph{push\_front} operation can be achieved by letting the \emph{firstFreeSlot} point to the reference that was pushed into the \emph{freeList} and setting the next reference to the head of the \emph{freeList}.
Iteration over the \emph{freeList} can be achieved by following the \emph{next} reference until it is null.
This means that the freelist can be updated without performing any allocations by itself.

Finally, in case that many elements are deallocated it is useful to erase blocks that do not store any elements, equivalently where all slots are free.
For this purpose we introduce the \emph{consolidate} function as shown in Algorithm~\ref{alg:consolidate}.
In the first part of the algorithm all elements of the free list are marked by a special value $\top$, which is a value that should not occur in any slot before consolidate is called, in lines 2 to 6.
For any block that only contains these special values it can be removed as shown in Line \ref{alg:consolidate:erase}.
The next part is to reconstruct the \emph{freeList} from the free elements in the block.
In practice these two looks are combined into one, maintaining whether the block contains elements that are not $\top$ and the \emph{freeList} during iteration over a block.
At the end of this iteration, the block is removed when the first condition holds and all entries of this block are removed from the \emph{freeList}, which can be done in constant time by remembering the starting element when entering this loop.

\begin{algorithm}[H]
  \caption{Consolidate}\label{alg:consolidate}
  \begin{algorithmic}[1]
    \Procedure{Consolidate}{}
    \For{slot $\in$ freeList}
      \State {slot $\gets \top$}
    \EndFor
    
    \For{block $\in$ blocks}
      \If {$\forall {slot \in block} {slot = \top}$}\label{alg:consolidate:erase}
        \State {blocks.erase(block)}
      \Else
        \For {slot $\in$ block}
          \If {slot $= \top$}
            \State{freeList.push\_back(slot)}
          \EndIf
       \EndFor
      \EndIf
    \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\noindent Although it might seem that it is very unlikely that blocks become completely empty this optimization had quite a large effect on the larger examples (in the order of ten to twenty percent).

\subsection{Alignment}

In a typical processor the accesses to main memory are cached through a number of increasingly larger, but slower caches. 
A \emph{cache line} is a block of consecutive memory that a processor fetches from main memory and stores in the cache at once. 
Whenever the processor loads or stores an address from main memory it actually fetches the whole block that contains this address.
Furthermore, these blocks are disjoint and so-called \emph{aligned} to multiples of the cache line \emph{width}.

In a modern processor the typical cache line has a width of 64 bytes.
This means that every memory access will fetch 64 consecutive bytes if it is not already in the cache. 
One optimization idea was to store the terms in the memory such that fetching its arguments does not cross cache line boundaries (and thus only require one fetch).
However, benchmarks indicated that this did not have a good impact on performance and it does carry a potential memory increase, which is also undesirable.

\subsection{Number Terms}

In some cases it is useful to store a numerical value as an argument to a term directly.
For example to gain better performance it might be useful to index terms in some data structure and store this index as an argument in the term.
Therefore, we extend the definition of terms such that $\naturalnumbers \subseteq \terms$.
The API is extended in the following way:

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{|l|l|}
      \hline
      $n \in \naturalnumbers$ & create\_int(n : $\naturalnumbers$) \\ \hline
    \end{tabular}
  \end{center}
  \caption{Extension to the API with number terms}
\end{figure}

\noindent The \texttt{value} function is defined that maps constant terms to the natural number value of which it was constructed.
In the implementation this numerical value is stored where normally the reference to the first argument is stored and a new function symbol $\texttt{aterm\_int} \in \functionsymbols_0$ is defined that is used to indicate such a special term.

\begin{thebibliography}{1}
  \bibitem{BJKO99}
  M.G.J.\ van den Brand, H.A.\ de Jong, P.\ Klint, and P.A.\ Olivier.
  Efficient Annotated Terms. Software - Practice \& Experience, 30:259-291, 2000.
\end{thebibliography}

\end{document}