\documentclass[10pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{todonotes}
\usepackage{tabularx}

\author{Maurice Laveaux}
\title{mCRL2 Term Library}

% Define numbered environments
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}

% Define various symbols
\newcommand{\character}{\alpha}
\newcommand{\naturalnumbers}{\mathbb{N}}

% Function symbols
\newcommand{\arity}{\alpha}
\newcommand{\symbols}{\mathcal{S}}
\newcommand{\functionsymbols}{\mathcal{F}}

% Lists
\newcommand{\listempty}{[\,]}
\newcommand{\listconcat}{+\!\!+}
\newcommand{\lists}{\mathcal{L}}

% Terms
\newcommand{\terms}{\mathcal{T}}
\newcommand{\function}{\text{function}}

\begin{document}
\maketitle

\noindent This document contains a description of the term library as implemented in the mCRL2 toolset.
The structure of the report is as follows.
In Section \ref{section:definitions} the underlying terms are formally defined.
In Section \ref{section:library} the programming interface and its high level requirements are presented.
In Section \ref{section:implementation} a generic implementation is described to highlight the system architecture and its intended behaviour.
In Section \ref{section:optimizations} the generic implementation is improved with several performance optimizations that have been applied.

\section{Definitions}\label{section:definitions}

We define \emph{terms} in the context of a set of \emph{function symbols}. 

\begin{definition}[Function symbols]
Let $\symbols$ be an arbitrary set of symbols.
The set of function symbols is defined $\functionsymbols \subseteq \symbols \times \naturalnumbers$. 
\end{definition}

\noindent The natural number indicates the \emph{arity} of a function symbol. The arity function $\arity$ is returns this arity for every function symbol, formally for a function symbol $(f, i)$ then $\arity((f, i))$ is equal to $i$.

\begin{definition}[Terms]
The set of terms $\terms$ is inductively defined. For terms $t_0, ..., t_n \in \terms$ and function symbol $f \in \functionsymbols$ where $\arity(f)$ is equal to $n$ the \emph{function application} $f(t_0, ..., t_n) \in \terms$.
\end{definition}

\noindent The function symbol in a function application is referred to as \emph{head} function symbol. 
Note that function symbols with arity zero are terms as well. Let $args$ be a function on terms that denotes the set of terms in a function application.
Formally, for a function application $f(t_0, ..., t_n)$, let $args(f(t_0, ..., t_n))$ be equal to the list of arguments $[t_0,...t_n]$.


\subsection{Classes}

There are several useful classes of terms that can be identified.
As an example the class of \emph{list} terms. 
Let $(\listconcat, 2)$ and $(\listempty, 0)$ be function symbols to define list concatenation and the empty list.

\begin{definition}[Term lists]
The set of \emph{list} terms $\lists$ is inductively defined as:

\begin{enumerate}
  \item The \emph{empty} list $(\listempty, 0) \in \lists$.
  
  \item If $t \in \terms$ and $l \in \lists$, then the \emph{concatenation} function application $\listconcat(t, l) \in \lists$.
\end{enumerate}
\end{definition}

\noindent Besides lists there are also different classes, such as \emph{term string} where a string is stored as part of the function symbol name and \emph{binary tree} where every left and right sub-tree is stored as arguments.

\section{Term Library}\label{section:library}

The term library provides the storage (in memory and on disk) of terms and function symbols. 
Formally, the term library stores a finite subset of terms $\terms' \subseteq \terms$ and finite subset of function symbols $\functionsymbols' \subseteq \functionsymbols$.
The library is designed with the following goals in mind:

\begin{enumerate}
	\item Minimize the amount of memory used to the set of terms.
	
	\item Fast creation (and deletion) of terms.
	
	\item Fast equality comparison between terms.
\end{enumerate}

\subsection{Application Programming Interface}

The library is implemented in the C++11 compliant subset of the C++ language. 
It consists of several classes that allow the user to create function symbols and term applications via their constructors. 
A constructor is a language construct that allow a user to instantiate an object of a specific class. 
The set of symbols $\symbols$ is represented by a set of strings, where each string indicates the name of a function symbol.
The relation between the mathematical elements and these constructors are listed in Figure \ref{table:apirelation}.

\begin{figure}[H]
\begin{center}
\begin{tabular}{|l|l|}
  \hline
Definition & API \\ \hline
$(name, arity) \in \functionsymbols$ & $\text{function\_symbol}(name, arity)$ \\ \hline
$f(t_0, ..., t_n) \in \terms$        & $\text{term\_appl}(f, t_0, ..., t_n)$ \\ \hline
\end{tabular}
\end{center}
\caption{The relation between the definition and the API}\label{table:apirelation}
\end{figure}

\noindent For the sub-classes of terms there are specific constructors defined as shown in figure \ref{table:apisubclasses}.

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{|l|l|}
      \hline
      Definition & API \\ \hline
      $(\listempty,0) \in \functionsymbols$ & \verb|function_symbol(<empty_list>,0)| \\ \hline 
      $(\listconcat,2) \in \functionsymbols$ & \verb|function_symbol(<list_constructor>,2)| \\ \hline 
      $\listconcat(t, l) \in \lists$ & \verb|term_list(t, l)| \\ \hline
    \end{tabular}
  \end{center}
  \caption{The relation between the definition and the API}\label{table:apisubclasses}
\end{figure}

\noindent Besides the creation of terms there are additional operators and functions defined.
There are binary operators to check equality (and inequality) of terms. 
Note that there is no semantic inequality defined, but from an implementation viewpoint this is useful to have.
This inequality is implemented by comparing the position where they are stored in memory.

There are also various functions defined to access the information carried by a term. 
There is a \verb|function| function that maps a term to the function symbol of which it was constructed. 
The \verb|arg| function is defined that takes a function application and an index as input and returns the argument term at the specified index.

\section{Implementation}\label{section:implementation}

In this section the architecture of the library is described and a generic implementation is described. 
The main architectural choice for this library is that terms and function symbols are maximally shared. 
This effectively implies that function applications refer to their arguments in the set $\terms'$ and a function symbol in the set $\functionsymbols'$.
These sets can be represented by an unordered set as described in the C++ standard template library (STL) which can be efficiently implemented using a hash table.
The reason for this sharing is to facilitate the minimize memory and constant time comparison goals stated in Section \ref{section:library}.
For the purpose of sharing we assume that there exists a \verb|shared_reference| class that internally counts the number of references to each term or function symbol.
The \texttt{term} and \texttt{function\_symbol} classes internally use this class.
A reference means that the user created a term or function symbol object, that a term occurs as an argument in a function application or that a function symbol occurs in a function application.

Now there is a function symbol pool class that stores the subset of function symbols $\functionsymbols'$ and a term pool to store the subset of terms $\terms'$.
The constructors described in the API use a single instance of each of these pools to ensure that every created term of function symbol is unique.
The pool classes will be described in detail in the next sections.

\subsection{Function symbol pool}

This class provides the \verb|create_function_symbol| method to define new function symbols.
It also provides the destruction of function symbols with a reference count of zero.

Internally it uses the set $\functionsymbols'$ which provides constant time insertion $\cup$, deletion $\setminus$ and contains $\in$ functions.

\subsubsection{Creating function symbols}

The constructor of a function symbol calls the following function to obtain a reference to an existing or new function symbol.

\begin{itemize}    
  \item create\_function\_symbol(name : String, arity : Nat) : $\functionsymbols$
\end{itemize}

\noindent This method either returns an existing function symbol in $\functionsymbols'$ or it results in a new function symbol $\text{function\_symbol}(name, arity)$. 
This new term will also be added to the current set of function symbols.
The pseudocode of this function becomes:

\begin{algorithm}[H]
 \caption{Creation of function symbols}\label{alg:create_function_symbol}
 \begin{algorithmic}[1]
  \Procedure{create\_function\_symbol}{$name, arity$}  
  \If {$\text{function\_symbol}(name, arity) \in \functionsymbols'$}
	 \State {\textbf{return} $\text{function\_symbol}(name, arity)$}
  \EndIf
  
  \State {$f \gets \text{construct}(name, arity)$}
    
  \State {$\functionsymbols' \gets \functionsymbols' \cup \{f\}$}
  \State {\textbf{return} $f$}
  \EndProcedure
\end{algorithmic}
\end{algorithm}

\noindent The value returned in the if-condition is an element that already exists in $F$.
In the implementation checking whether $\text{function\_symbol}(name, arity) \in \functionsymbols'$ can be done without constructing the function symbol, which can be expensive.
The \emph{construct} function allocates a new function symbol object on the heap with the given name and arity.

For each reference the reference counter indicates the amount of times that an object is referred to. 
For cleaning up objects two different approaches can be taken. 
The \emph{destructor} of a class is a function that is called whenever an instance of that class is destroyed.
It is possible to immediately destroy the object when its reference count becomes zero. 
This approach will be referred to \emph{direct-destruction}. 
Another approach is to periodically clean up all terms with a zero reference count. 
This approach will be referred to as \emph{garbage collection}.

For function symbols the \emph{direct-destruction} method is used, which means that the allocated space is immediately freed whenever its reference count becomes zero.
This destruction is implemented by the \verb|destroy| function that deallocates the memory used and removes it from the set $S$.

\begin{algorithm}[H]
 \caption{Destruction of function symbols}\label{alg:destroy_function_symbol}
 \begin{algorithmic}[1]
  \Procedure{destroy}{$f$}  
  \State {$deallocate(f)$}    
  \State {$\functionsymbols' \gets \functionsymbols' \setminus \{f\}$}
  \EndProcedure
\end{algorithmic}
\end{algorithm}

\noindent The \emph{destroy} function cleans up the heap memory used by the function symbol $f$.

\subsection{Term pool}
To be able to share terms, all constructors interact with a single instance of a class called \emph{term\_pool}.
The term pool is the class that stores the set of terms $\terms'$.
This class provides the \emph{create\_appl} method to define new function applications.
It also provides the destruction of terms with a reference count of zero. 

\subsubsection{Creating terms}

The constructor of a function application calls the following function to obtain a reference to an existing or new term.

\begin{itemize}    
	\item create\_appl(f : $\functionsymbols$, $t_0, ..., t_n : \terms$) : $\terms$
\end{itemize}

\noindent The function symbol $f$ and terms $t_0$ to $t_n$ should be elements of the current subset of stored function symbols $\functionsymbols'$ and terms $\terms'$ respectively.
The pseudocode of this function is:

\begin{algorithm}[H]
 \caption{Creation of term applications}\label{alg:creation}
 \begin{algorithmic}[1]
  \Procedure{create\_appl}{$f,t_0,...,t_n$}  
  \If {$\text{term\_appl}(f, t_0,...t_n) \in \terms'$}
	 \State {\textbf{return} $\text{term\_appl}(f, t_0,...t_n)$}
  \EndIf
  
  \State {$t \gets \text{construct}(f,t_0,...,t_n)$}
  
  \If {should-collect-garbage()}
   \State {collect()}
  \EndIf
  
  \State {$\terms' \gets \terms' \cup \{t\}$}
  \State {\textbf{return} $t$}
  \EndProcedure
\end{algorithmic}
\end{algorithm}

\noindent The terms are stored on the heap as follows:

\begin{center}
\begin{tabular}{|c|c|}
\hline
Name & Size \\ \hline
function symbol reference & 8 \\ \hline 
reference counter & 8 \\ \hline
$t_0$ reference & 8 \\ \hline
... & ... \\ \hline
$t_n$ reference & 8 \\ \hline
\end{tabular}
\end{center}

\noindent A reference is typically stored as a pointer; which requires 8 bytes on a 64bit program.

The boolean function \emph{should-garbage-collect} is used to decide when garbage collection should be performed.
The garbage collection itself is implemented by the \emph{collect} function.
Currently the \emph{should-garbage-collect} function is implemented by using a counter that is decremented on every call to \emph{should-garbage-collect}.
Whenever this counter reaches zero the function returns true.
During garbage collection this counter is then set to the number of terms in $\terms'$, which is equal to $|S|$.

\subsubsection{Garbage collection}


The advantage of garbage collection is that terms with a reference count of zero can be reused instead of being destroyed.
In this case it is not necessary to allocate this term again, but only to increase its reference counter. 
Although not explained in detail, in practice it was observed that during term rewriting this occurs often. 
The garbage collection is implemented by calling destroy on every term with a reference count of zero, as shown in the following pseudocode:

\begin{algorithm}[H]
\caption{Garbage collection of terms}\label{alg:collect}
\begin{algorithmic}[1]
\Procedure{Collect}{}
	\For {$t \in \terms'$}
    \If {$\text{reference-count}(t) == 0$}
      \State{destroy(t)}
    \EndIf
  \EndFor
  
  \State{collect-countdown $\gets |\terms'|$ }
\EndProcedure
\end{algorithmic}
\end{algorithm}

\noindent The \emph{destroy} method recursively destroys all arguments which have a single reference, because that reference is the current function application.

\begin{algorithm}[H]
\caption{Destroying individual terms}\label{alg:destroy}
\begin{algorithmic}[1]
\Procedure{Destroy}{$t : \terms'$}
  \For {$p \in args(t)$}
    \If {$\text{reference-count}(p) == 1$}
      \State {Destroy($p$)}    
    \EndIf
  \EndFor
  
  \State {$\terms' \gets \terms' \setminus \{t\}$}
  \State {deallocate($t$)}
\EndProcedure
\end{algorithmic}
\end{algorithm}

\noindent The \emph{deallocate} function frees the heap memory used by this term.
Note that this function prematurely destroys arguments with a single reference count. 
The reason for this is that the function \texttt{arg} is no longer defined for $t$ after it has been deallocated. 

\subsection{Data structures}

In this section the data structures in the implementation are described in detail.

\subsection{Reference counting}

The function symbol and term classes in the API internally have a shared reference to the maximally shared function symbol or term.
To make sure that this function symbol or term can also be cleaned up at some point a so-called reference counter is introduced that keeps track of the number of references to it.

The shared reference is implemented by a class named \texttt{shared\_reference} which consists of a reference and a reference counter. 
The invariant states that the reference counter is always equal to the number of instances that point to the same referred term. 
In C++ there are a number of operators to construct, move and copy classes.
A move is an operator where an object is constructed from another object, but the other object can be left in an undefined state.
The reference count invariant is satisfied by implementing these operations in the following way:

\begin{enumerate}
  \item When a \texttt{shared\_reference} instance is constructed from a reference its reference count is incremented by one.
  
  \item When a \texttt{shared\_reference} instance is copy-constructed its reference count is incremented by one.
  
  \item When a \texttt{shared\_reference} instance is move-constructed the reference count is kept the same, but the\texttt{shared\_reference} instance that was moved from will become a null reference.
  
  \item When a \texttt{shared\_reference} instance is assigned to its current reference count is decremented by one.
  The reference count of the assigned reference is incremented by one.
  
  \item When a \texttt{shared\_reference} instance is move-assigned its current reference count is decremented by one. The \texttt{shared\_reference} instance that was moved from will become a null reference.
  
  \item When a \texttt{shared\_reference} is destructed the reference count will be decremented by one. 
\end{enumerate}

\noindent For terms and function symbols all shared references are constructed with a default term or function symbol respectively. 
Whenever the reference count for a reference is equal to zero the referred to term can be cleaned up.
In the case of function symbols this immediately triggers the destroy function.

\subsection{Hash table}

The terms and functions symbols are both stored in a set $S$ which provides constant time insertion $\cup$, deletion $\setminus$ and contains $\in$ functions.
It was mentioned that these operators could be implemented using a hash-table.
In this section the implementation of that hash-table will be described.

The hash-table will store the set terms and function symbols.
To be able to find, insert and delete elements we need to define a hash function and an equals function.
The hash function is a unary function that takes a term (or function symbol) and returns a natural number.
For terms the hash function is defined by combining the values of all the references.
This results in the following pseudocode:

\begin{algorithm}[H]
 \caption{Hashing terms}\label{alg:create_term}
 \begin{algorithmic}[1]
  \Procedure{hash}{$f(t_0, ..., t_n)$} 
  \State {$hnr \gets hash(f)$}
  \For {$t \in t_0, ..., t_n$}
    \State {$hnr \gets combine(hnr, t)$}
  \EndFor 
  \State {\textbf{return} $hnr$}
  \EndProcedure
\end{algorithmic}
\end{algorithm}

\noindent Notice that the term is constructed from references to the function symbol and the arguments.
Instead of hashing these by value the hash can also be constructed from the value of their pointers which is often faster to compute in practice.
The combine function takes a hash number and a term and combines the result into a new hash number.
For function symbols the hash function is the combination of a hash for its name and the arity.

The equivalence between terms can be determined by comparing the references of the function symbols and the references for each of its arguments.
If any do not match the terms are not equivalent.

The hash table that was chosen is a closed addressing hash table with singly linked-list bucket.

An alternative hash table that had been tried is called hopscotch hashing.
This is an open addressing, or closed hashing, which means that collisions are resolved by means of probing.
Generally probing can become inefficient on a high number of collisions, which means a high load factor, because of the number of number of probes.
Hopscotch hashing partially resolves this issue by having an upper bound on the number of probes.

As in most open addressing hash table it uses a continuous array of $n$ so-called \emph{buckets}.
For each bucket a \emph{neighborhood} is defined by a small collection of neighboring buckets.
Let $H$ be natural number, typically 32 or 64 bits, that defines the size of a neighborhood.
This can then be visualized as virtual bucket of the current bucket and $H-1$ consecutive buckets.
Hopscotch hashing maintains the invariant that each element is stored inside of this virtual neighborhood of the bucket that it hashes into.
This invariant is maintained by moving elements inside of their neighborhood when the neighborhood of the inserted element is full.
However, if this is not possible the hash-table is resized and all of the elements are rehashed.

The hopscotch hashing can be sped up by maintaining information on which entries in a neighborhood are already filled.
As the neighborhood size is typically 32 or 64 bit that information can be stored in a single word where each bit indicates when that index is filled.

However, the downside of this approach was that by resolving collisions on top of other possible values the number of required equivalence checks grows.
For terms checking equivalence has a complexity in the arity of the corresponding function symbol.
This results in an about 10-15 percent slowdown compared to the simple linked list hashtable.

\section{Optimizations}\label{section:optimizations}

There are several optimizations that can be performed on this generic implementation.

\subsection{Term pool per arity}

Most function applications only consist of a small number of arguments. 
Let $k$ be a constant such that a function application is \emph{small} whenever its arity is less than or equal to $k$. 
We will use $\terms^i$, for any natural number $i$, to denote a subset of $\terms$ with function symbols that have an arity equal to $i$. 

Now, instead of having one pool to store the finite subset $\terms' \subseteq \terms$, there will be a number of term pools:

\begin{itemize}
  \item For small terms, $k$ different pools to store $\terms^0 \cup ... \cup \terms^k \subseteq \terms'$.
    
  \item A pool to store the set of terms $\terms'' \subset \terms'$ that do no occur in the other pools, i.e. $\terms'' = \terms' \setminus (\terms^0 \cup ... \cup \terms^k)$.
\end{itemize}

\noindent Note that all pools are disjoint, i.e. $\terms^0 \cap ... \cap \terms^k \cap \terms'' = \emptyset$ and all pools combined store the whole subset, i.e. $\terms^0 \cup ... \cup \terms^k \cup \terms'' = \terms'$. 
The interface of the term pool remains unchanged. 
Internally this term pool uses the arity of a function symbol and the creation method to decide which pool will be used to create the term. 
For example calls to \texttt{create\_appl(f)} will always go to the pool storing $\terms^0$.

The effect of these changes is that the complexity for all loops over the arguments of function symbols with an arity up to and including $k$ will become constant. 
The decision procedure has constant complexity as well.

Less theoretical this enables compiler optimizations such as loop unrolling. 
This optimization reduces the number of branch misses which increases the effective run-time performance as well.
In practice this optimization performed well.

\subsection{Alternative reference counting}

If terms can be accessed by multiple threads at the same time it is necessary to introduce \emph{atomic} reference counters.
These atomic reference counters make sure that no data races can occur when incrementing or decrementing its value.
However, in practice it was observed that atomic reference counters slow down the performance of creating terms by a factor of four.
Here, we introduce a way to relax the reference counting for function application arguments.

Instead of considering function application arguments as a reference, they can be considered as a \emph{weak reference}.
A weak reference is a reference that does not change the reference counter of the referred to term.
If the arguments of a function application are weak references then the number of reference count increments and decrements can be reduced.
However, this means that the garbage collection has to be adapted as a reference count of zero does not necessarily imply that the term is not referred to via a function application.

The garbage collection that will be described here is often referred to as \emph{tracing garbage collection}. 
Its basis is that all terms that are \emph{unreachable} will be destroyed in a two-phase algorithm called \emph{mark} and \emph{sweep}.

\begin{algorithm}[H]
  \caption{Garbage collection of terms with weak references}\label{alg:collect}
  \begin{algorithmic}[1]
    \Procedure{Collect}{}
    \State{Mark()}
    \State{Sweep()}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\noindent Consider the terms as a graph where the set of vertices are given by $\terms'$ and the edges are given by a relation between function applications and their arguments.
Every term with a reference count above zero is reachable by definition.
The set of these terms is called the \emph{root} set.
Now from this root set, every term that is reachable by following the edges in the graph is reachable as well and should not be destroyed.

The set of reachable nodes can be determined by recursively marking the reachable nodes, this is implemented by the \emph{mark} function as follows.
Indicating whether a term is reachable is done by coloring the nodes in this graph, which will be referred to as a mark.
A term can be marked by using the function \emph{set-mark} and the mark can be removed by using \emph{remove-mark}.
The function \emph{is-marked} returns true if and only if that term has been marked.

\begin{algorithm}[H]
  \caption{Marking reachable terms}\label{alg:mark}
  \begin{algorithmic}[1]
    \Procedure{Mark}{}
    \For {$t \in S$}
      \If {$\text{reference-count}(t) > 0$}
        \State{Mark(t)}
      \EndIf
    \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\noindent The \emph{Mark} function applied to a term will mark itself and all of its arguments recursively as reachable.

\begin{algorithm}[H]
  \caption{Marking an individual term}\label{alg:markterm}
  \begin{algorithmic}[1]
    \Procedure{Mark}{$t : \terms'$}
    \If{$\neg$is-marked($t$)}
      \State{set-mark($t$)}
    
      \For {$p \in args(t)$}
        \State{Mark(p)}
      \EndFor
    \EndIf
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\noindent Now, all terms that are not marked, and as such not reachable, can be deallocated and removed from the set of terms $S$.
It should also remove the mark of marked terms such that the next garbage collection can be performed.
This is implemented by the \emph{Sweep} function as follows:

\begin{algorithm}[H]
  \caption{Sweeping terms that are no reachable}\label{alg:sweep}
  \begin{algorithmic}[1]
    \Procedure{Sweep}{}
    \For {$t \in S$}
      \If {$\neg \text{is-marked}(t)$}
        \State{$S \gets S \setminus \{t\}$}
        \State{deallocate($t$)}
      \Else
        \State{remove-mark($t$)}
      \EndIf
    \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\noindent After this procedure the memory used by all terms that are not reachable has been freed.

\subsection{Null term}

Instead of introducing a default term that is used whenever the \texttt{shared\_ptr} is default constructed we can introduce an actual \emph{null} reference. 
This change breaks the invariant that any term always has an existing shared reference. 
That requires the \texttt{shared\_ptr} to check whether is has a valid reference before trying to adapt its reference counter. 
The advantage of this change is a reduction in the number of reference count adaptations that have to be performed on the default term.

For the shared reference a function called \emph{defined} is introduced that checks whether the shared reference is not equal to \emph{null}.

In the 1394 protocol state space generation with the options \texttt{--cached} this optimization reduced the number of reference count increment and decrements by ten percent. The run-time performance was almost unaffected. However, in the case of atomic reference counters this had about 11 percent speed-up on the resulting state space generation.

\subsection{Block allocator}

The \texttt{allocate}, \texttt{construct} and \texttt{deallocate} functions are part of the allocator interface as defined in the STL.
The \texttt{construct} function calls \texttt{allocate} and then the constructor of the object.
The default allocator is wrapper around \texttt{new} and \texttt{delete}.
These functions are a wrapper around \texttt{malloc} and \texttt{free}.
Although no specific implementation is required for these functions they typically call kernel functions to obtain memory from the operating system for each call.
In the Linux kernel a slab allocator is used that has no internal fragmentation for powers of two and a page size is typically 4KB. 
Compared to that, a single term of arity three only requires $40$ bytes, which is not a power of two and also small.

The amount of terms allocated is typically very large and the exact size in bytes of each term is known beforehand.
Therefor a useful approach is to allocate a block of memory, for example 4KB, and return references to slots in this block.
A slot is space in a block that is large enough to store one element.
 
The block allocator has a single linked list of blocks called $blocks$.
Each block can store \texttt{ElementsPerBlock} number of elements, which is equal to the number of slots in a block.
The allocator stores a \texttt{currentIndex} of the first slot in the block that has never been used.
To keep track of slots that have been deallocated in the mean time a \emph{freeList} is used.

\begin{algorithm}[H]
  \caption{Allocate}\label{alg:allocate}
  \begin{algorithmic}[1]
    \Procedure{Allocate}{}
    \If {$\neg$freeList.empty()}
      \State {\textbf{return} freeList.pop\_front()}
    \EndIf
    
    \If {currentIndex $>=$ ElementsPerBlock}
      \State {blocks $\gets$ blocks.push\_front()}
      \State {currentIndex $\gets 0$}
    \EndIf  
    
    \State {firstBlock $\gets$ blocks.front()} 
    \State {slot $\gets$ firstBlock[currentIndex]} 
    \State {currentIndex $\gets$ currentIndex + 1}
    \State {\textbf{return} slot}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\noindent The deallocation of a term is the same as adding it to the freelist.
This can be efficiently done by changing its next reference to \texttt{firstFreeSlot} and setting the first free slot to the new head of the freelist.

\begin{algorithm}[H]
  \caption{Deallocate}\label{alg:deallocate}
  \begin{algorithmic}[1]
    \Procedure{Deallocate}{Reference r}
      \State {freeList.push\_front(r)}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\noindent Finally it would be useful to be able to erase blocks that don't store any elements.
For this purpose the \emph{consolidate} function was introduced, see Algorithm \ref{alg:consolidate}.
First, recall that all elements in the free list can be visited by following the next reference starting from the \emph{firstFreeSlot}.
In the first part of the algorithm all elements of the free list are marked by a special value $\top$, which is a value that should not occur in any slot before consolidate is called, in lines 2 to 6.
The next part is to reconstruct the \emph{freeList} from the free elements in the block.
Line \ref{alg:consolidate:erase} checks whether the block only contains elements that are free.
If that is the case then this block can be erased from the list of blocks. 
This check can be efficiently implemented by checking it in the for loop over all slots in the block.

\begin{algorithm}[H]
  \caption{Consolidate}\label{alg:consolidate}
  \begin{algorithmic}[1]
    \Procedure{Consolidate}{}
    \For{slot $\in$ freeList}
      \State {slot $\gets \top$}
    \EndFor
    
    \For{block $\in$ blocks}
      \If {$\forall {slot \in block} {slot = \top}$}\label{alg:consolidate:erase}
        \State {blocks.erase(block)}
      \Else
        \For {slot $\in$ block}
          \If {slot $= \top$}
            \State{freeList.push\_back(slot)}
          \EndIf
       \EndFor
      \EndIf
    \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\noindent An optimization that can be performed in the block allocator it to store the \emph{freeList} inside the slots of the blocks directly.
This can be implemented as follows.
The first slot in this free list is pointed to by \emph{firstFreeSlot}.
The \emph{freeList} can then be stored by storing the \emph{next} reference, which contains the reference to the next element in the list, in place of the slots.
We define the invariant that all slots that are reachable by following next references after \texttt{firstFreeSlot} are part of the freelist.
This means that the \emph{freeList} is empty when the \emph{firstFreeSlot} points to null.
The \emph{push\_front} operation can be achieved by letting the \emph{firstFreeSlot} point to the reference that was pushed into the \emph{freeList} and setting the next reference to the head of the \emph{freeList}.
Iteration over the \emph{freeList} can be achieved by following the \emph{next} reference until it is null.

In practice the consolidate function is only able to erase relatively few blocks.

\subsection{Alignment}

In a typical processor design the accesses to main memory are cached through a number of increasingly larger, but slower caches. 
A \emph{cache line} is a block of consecutive memory units that a processor fetches from main memory at once and stores in a cache. 
When a processor wants to load or store an address from main memory it will actually load the whole block that contains this address. 
The start of each block is also also \emph{aligned} to the width of the cache line. 
This means that its first address is a multiple of the cache line width.

In a modern processor the typical cache line has a width of 64 bytes.
This means that every memory access will fetch 64 consecutive bytes. 
The fetches are also aligned to 64 bytes which means that the lowest address fetched is a multiple of 64. 
The optimization idea was to store the terms in memory in such a way that accesses to its members does not cross cache line boundaries. 
This would otherwise require multiple cache lines to be fetched.
However, benchmarks indicated that this did not have a good impact on performance and it does carry a potential memory increase, which is also undesired.

\subsection{Integral terms}

In term rewriting with substitutions it is required to have a mapping from terms representing variables to their value. 
This is a mapping between terms. 
For this purpose a hash map can be used. 
This has constant complexity, but also a small overhead for computing the hash number. 
Better performance can be achieved by storing this mapping in an array. 
A value will then be used to index a position in this array to look up the term for its value. 
This index has to be dense and a unique index can be generated when required.

In practice this index value is stored as last argument in the function application. 
Consider the following variable term $var(a, b, c)$, whenever $5$ would be the next index available this term becomes $var(a, b, c, 5)$ and in the substitution mapping array the index $5$ will return the value for this variable.
To be able to store natural numbers as argument to a function application the natural numbers will become terms as well. 
Formally the set of terms $\terms$ will be extended as follows:

\begin{itemize}
  \item If $t$ is a \emph{constant} term, i.e. $t \in \naturalnumbers$ then $t \in \terms$.
\end{itemize}

\noindent The API is extended in the following way:

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{|l|l|}
      \hline
      $c \in \naturalnumbers, c \in \terms$ & create\_int(n : $\naturalnumbers$) \\ \hline
    \end{tabular}
  \end{center}
  \caption{Extension to the API with constant terms}
\end{figure}

\noindent The \texttt{value} function is defined that maps constant terms to the natural number value of which it was constructed.



\end{document}